# Large Language Models

Week two explores the architecture and usage of modern large language models.

## Model Families
- GPT-3/4 and Claude
- open source alternatives

## Transformer Architecture
An overview of attention mechanisms, positional encoding and the training objective behind autoregressive models.

## Using Hosted APIs
Practical tips for sending prompts, handling rate limits and interpreting model outputs. Examples show the differences between providers.

## Ethical and Practical Concerns
Discuss data privacy, bias and the environmental impact of training large models.
